{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re # Регулярные выражения.\n",
    "import pymorphy2 # Морфологический анализатор.\n",
    "from collections import Counter # Не считать же частоты самим.\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.model_selection import validation_curve, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение от которого отталкиваться - медианы по подкатегориям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = pd.read_csv('train_4_col.csv', delimiter='\\t')\n",
    "train_df1 = train_df1.loc[:,['id','price']]\n",
    "train_df2 = pd.read_csv('train_4_col_2.csv', delimiter='\\t')\n",
    "train_df2 = train_df2.loc[:,['id','category','subcategory']]\n",
    "train_df = train_df1.merge(train_df2, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# медины по категориям, подкатегориям\n",
    "meds_cat = train_df.groupby('category')['price'].median()\n",
    "meds_subcat = train_df.groupby('subcategory')['price'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_subcat.to_frame().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_3_col_2.csv', delimiter='\\t')\n",
    "test_df = test_df.loc[:,['id','category','subcategory']]\n",
    "test_df = test_df.merge(meds_subcat.to_frame(), how='left', on='subcategory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = meds_subcat.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# новая категория в тесте\n",
    "test_df2 = pd.read_csv('test_3_col_2.csv', delimiter='\\t')\n",
    "test_df2[test_df2['subcategory']==2301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df3=pd.read_csv('test_3_col.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df3[test_df3['id']=='0fe6723933ab5606918dd9a5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['category']==23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df.price.isna(),'price'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# медианы по подкатегориям (в копейках), нули в новой подкатегории\n",
    "test_df.loc[:,['id','price']].to_csv('subm1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# автомобили. заполним медианой 102\n",
    "test_df.loc[test_df['price']==0,'price'] = 11500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[:,['id','price']].to_csv('subm2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['price'] = test_df['price']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нужны рубли\n",
    "test_df.loc[:,['id','price']].to_csv('subm3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конвертация fields в json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('train_sample.pckl', \"rb\")\n",
    "train_sample = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fields = pd.read_csv('train_4_col_3.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample.fields[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = json.loads(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(js[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fields.loc[:,\"fields_json\"] = train_fields.fields.replace(\"None\", \"\\\"\\\"\").replace(\"True\",\"1\").replace(\"False\",\"0\").replace(\"\\'\", \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fields.fields_json[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохранили fields в формате json\n",
    "train_fields.to_csv(\"my_train_4_col_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fields.fields[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample.fields[0][2]['field']['field_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample.fields[110]['110']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fields.fields[110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=\"category\", y=\"price\", data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=train_df[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = pd.read_csv('train_4_col.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2 = pd.read_csv('train_4_col_2.csv', delimiter='\\t')\n",
    "train_df = train_df1.merge(train_df2, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['Unnamed: 0_x', 'Unnamed: 0_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('new_text_pr_cats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph=pymorphy2.MorphAnalyzer()\n",
    "def getMeaningfullWords(text):\n",
    "    words=[]\n",
    "    tokens=re.findall('[А-Яа-яЁёA-Za-z]+\\-[А-Яа-яЁёA-Za-z]+|[А-Яа-яЁёA-Za-z]+', str(text))\n",
    "    for t in tokens:\n",
    "        pv=morph.parse(t)\n",
    "        for p in pv:\n",
    "            if p.tag.POS in ['ADJF', 'NOUN', 'VERB']:\n",
    "                words.append(p.normal_form)\n",
    "                break\n",
    "    return words\n",
    "def getMeaningfullString(txt):\n",
    "    res = ' '.join(getMeaningfullWords(txt))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['new_name'] = train_df['name'].apply(func = getMeaningfullString)\n",
    "train_df['new_description'] = train_df['description'].apply(func = getMeaningfullString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['new_description'] = train_df['description'].apply(func = getMeaningfullString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rlmse_score(y_test, y_hat):\n",
    "    # Your code here\n",
    "    n = len(y_test)\n",
    "    rlmse = np.sqrt(1/n*np.sum(np.square(np.log(y_test+np.ones(n)) - np.log(y_hat + np.ones(n)))))\n",
    "    return rlmse\n",
    "\n",
    "# Эту функцию трогать не надо\n",
    "def rlmse_scorer(estimator, X, y):\n",
    "    y_hat = estimator.predict(X)\n",
    "    \n",
    "    return rlmse_score(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ohe = OneHotEncoder(categorical_features = [1])\n",
    "X_subcat = ohe.fit_transform(train_df.loc[:,['category','subcategory']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subcat = X_subcat.toarray()[:,0:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subcat = X_subcat.toarray()[:,0:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subcat.tofile(\"X_subcat_array.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['price']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.to_csv(\"y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_name = CountVectorizer()\n",
    "#counter_descr = CountVectorizer()\n",
    "X_name = counter_name.fit_transform(train_df['new_name'].values)\n",
    "#X_descr = counter_descr.fit_transform(train_df['new_description'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subcat = sp.csr_matrix(X_subcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subcat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = sp.hstack((X_subcat, X_name, X_descr))\n",
    "X = sp.hstack((X_subcat, X_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_train_test, y_train, y_train_test = train_test_split(X_new, y_new, test_size=0.3, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor()\n",
    "\n",
    "regressor.fit(X_train,y_train)\n",
    "y_hat = regressor.predict(X_train_test)\n",
    "#out_of_bag_prediction_for_x = regressor.oob_prediction_\n",
    "\n",
    "#print(rlmse_score(out_of_bag_prediction_for_x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rlmse_score(y_train_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = ElasticNet(alpha=0.1, l1_ratio=10)\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = regressor.predict(X_train_test)\n",
    "print(rlmse_score(y_train_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_range = np.logspace(-3, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_ratio = 0.5\n",
    "10 - 6.198857525607565\n",
    "1.0 - 6.1896718854981465\n",
    "0.1 - 5.762364497363481\n",
    "0.01 - 5.594739242709756\n",
    "\n",
    "l1_ratio = 10\n",
    "10 - 6.19244423861566\n",
    "0.01 - 5.578056005862723\n",
    "0.001 - 75.15656556569385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_range = np.logspace(-3, 5, 20)\n",
    "for alpha in alpha_range:\n",
    "    regressor = ElasticNet(alpha=alpha, l1_ratio=0.5)\n",
    "    regressor.fit(X_train,y_train)\n",
    "    y_hat = regressor.predict(X_train_test)\n",
    "    print(alpha, '\\t', rlmse_score(y_train_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# булевские переменные в 0-1.\n",
    "Формируем фичи - 6 столбцов с булевскими переменными, 250 подкатегорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('train_hack.pckl', \"rb\")\n",
    "train_df = pickle.load(f)\n",
    "feature_columns = ['can_buy','can_promote','contacts_visible','delivery_available','mortgage_available','payment_available']\n",
    "train_df_features = train_df.loc[:,feature_columns]\n",
    "train_df_features = train_df_features * 1\n",
    "X = np.hstack((train_df_features,X_subcat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_features.to_csv('train_df_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_features = pd.read_csv('train_df_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((train_df_features.loc[:,['delivery_available','payment_available']],X_subcat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_features = train_df_features.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.tofile(\"x.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.fromfile(\"x.csv\", sep=\"\\t\")\n",
    "X = X.reshape((1748890, 256))\n",
    "y = pd.read_csv(\"y.csv\",header=None)\n",
    "y=y.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test_hack.pckl', \"rb\")\n",
    "test_sample = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_subcat = ohe.transform(test_sample.loc[:,['category','subcategory']])\n",
    "X_test_subcat = X_test_subcat.toarray()[:,0:250]\n",
    "feature_columns = ['can_buy','can_promote','contacts_visible','delivery_available','mortgage_available','payment_available']\n",
    "test_df_features = test_sample.loc[:,feature_columns]\n",
    "test_df_features = test_df_features * 1\n",
    "X_test = np.hstack((test_df_features,X_test_subcat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.loc[:,'price'] = y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.loc[:,['id','price']].to_csv('subm4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.loc[:,'price'] = y_hat * 100\n",
    "test_sample.loc[:,['id','price']].to_csv('subm5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# аномалии как крайние значения\n",
    "идея: мусором считать все, что не повторяется в других объявлениях (не успела)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# уберем аномалии\n",
    "X_new = X[train_df.groupby(\"subcategory\").price.\\\n",
    "      transform(lambda x : (x<x.quantile(0.95))&(x>(x.quantile(0.05)))).eq(1)]\n",
    "y_new = y[train_df.groupby(\"subcategory\").price.\\\n",
    "      transform(lambda x : (x<x.quantile(0.95))&(x>(x.quantile(0.05)))).eq(1)]\n",
    "regressor = ElasticNet(alpha=0.1, l1_ratio=10)\n",
    "regressor.fit(X_new,y_new)\n",
    "# rlmse на сплите = 2.568335764977625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.loc[:,'price'] = y_hat\n",
    "test_sample.loc[:,['id','price']].to_csv('subm6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотритм по субкатегориям частоты\n",
    "cat_counts = train_df.groupby('subcategory')['price'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# среди feature_columns = ['can_buy','can_promote','contacts_visible','delivery_available','mortgage_available','payment_available']\n",
    "# только 'delivery_available' и 'payment_available' имеют разные значения\n",
    "feature_columns =['delivery_available', 'payment_available']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subcat = train_df['subcategory']\n",
    "\n",
    "\n",
    "# X_2 = np.delete(X, [3,5], 1)\n",
    "# все равно плохо на такой выборке valid_scores = array([[6.21722723, 6.27396792, 6.09464087],\n",
    "#       [6.26858403, 6.30624024, 6.06554924],\n",
    "#       [6.26742859, 6.30514385, 6.063095  ],\n",
    "#       [6.26735874, 6.30507743, 6.0629456 ]])\n",
    "# попробуем убрать первые 4, оставить только субкатегорию\n",
    "# блин! наоборот надо было. оставить 3 и 5\n",
    "\n",
    "\n",
    "#X_2 = np.delete(X, [0,1,2,4],1)\n",
    "#array([[5.67051601, 5.69405841, 5.69651048],\n",
    "#       [6.12368325, 6.16309129, 5.92382398],\n",
    "#       [6.2627221 , 6.30057416, 6.05835798],\n",
    "#       [6.26513786, 6.3029242 , 6.06070606]])\n",
    "#X_2 = np.delete(X, [0,1,2,3,4,5],1)\n",
    "#array([[6.21722723, 6.27396792, 6.09464087],\n",
    "#      [6.26858403, 6.30624024, 6.06554924],\n",
    "#       [6.26742859, 6.30514385, 6.063095  ],\n",
    "#       [6.26735874, 6.30507743, 6.0629456 ]])\n",
    "\n",
    "# уберем аномалии\n",
    "# X_2 = np.delete(X, [0,1,2,4],1)\n",
    "\n",
    "# X_new = X_2[train_df.groupby(\"subcategory\").price.\\\n",
    "#      transform(lambda x : (x<x.quantile(0.95))&(x>(x.quantile(0.05)))).eq(1)]\n",
    "# y_new = y[train_df.groupby(\"subcategory\").price.\\\n",
    "#      transform(lambda x : (x<x.quantile(0.95))&(x>(x.quantile(0.05)))).eq(1)]\n",
    "X_2 = np.delete(X, [0,1,2,4],1)\n",
    "\n",
    "#X_new = X_2[train_df.groupby(\"subcategory\").price.\\\n",
    "#      transform(lambda x : (x<x.quantile(0.95))).eq(1)]\n",
    "#y_new = y[train_df.groupby(\"subcategory\").price.\\\n",
    "#      transform(lambda x : (x<x.quantile(0.95))).eq(1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['subcategory'] = train_df2['subcategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good = train_df.groupby(\"subcategory\").price.\\\n",
    "#      transform(lambda x : (x<x.quantile(0.95))).eq(1)\n",
    "good = train_df.groupby(\"subcategory\").price.\\\n",
    "      transform(lambda x : (x<x.quantile(0.95))&(x>(x.quantile(0.05)))).eq(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tr.price = good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subcat = train_df['subcategory'][train_df.groupby(\"subcategory\").price.\\\n",
    "#      transform(lambda x : (x<x.quantile(0.95))&(x>(x.quantile(0.05)))).eq(1)]\n",
    "#subcat = train_df['subcategory'][train_df.groupby(\"subcategory\").price.\\\n",
    "#      transform(lambda x : (x<x.quantile(0.95))).eq(1)]\n",
    "#train_df.groupby(\"subcategory\").price.\\\n",
    "#      transform(lambda x : (x<x.quantile(0.95))).eq(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=111)\n",
    "alpha_range = [0.01, 0.1, 1, 2]\n",
    "train_scores, valid_scores = validation_curve(regressor, X_new, y_new, param_name=\"alpha\", param_range=alpha_range,\n",
    "                                              cv=cv.split(X_new, subcat), scoring=rlmse_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = pd.concat([pd.DataFrame(X_2), good], axis=1)\n",
    "X_train, X_train_test, y_train, y_train_test = train_test_split(X_tr, y, test_size=0.3, random_state=111)\n",
    "y_train = y_train.loc[X_train.price == True]\n",
    "X_train = X_train.loc[X_train.price == True]\n",
    "X_train = X_train.iloc[:,0:252]\n",
    "X_train_test = X_train_test.iloc[:,0:252]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressor = ElasticNet(alpha=0.1, l1_ratio=10)\n",
    "# 2.9643305151603365\n",
    "regressor = LinearRegression()\n",
    "# 1.7119132454915786\n",
    "regressor.fit(X_train,y_train)\n",
    "print(rlmse_scorer(regressor, X_train_test, y_train_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit\n",
    "y_train = y.loc[X_tr.price == True]\n",
    "X_train = X_tr.loc[X_tr.price == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.iloc[:,0:252]\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test_hack.pckl', \"rb\")\n",
    "test_sample = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.loc[test_sample['subcategory'] == 2301, 'subcategory'] = 102\n",
    "X_test_subcat = ohe.transform(test_sample.loc[:,['category','subcategory']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_subcat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_subcat = X_test_subcat.toarray()[:,0:250]\n",
    "feature_columns = ['delivery_available','payment_available']\n",
    "test_df_features = test_sample.loc[:,feature_columns]\n",
    "test_df_features = test_df_features * 1\n",
    "X_test = np.hstack((test_df_features,X_test_subcat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_subcat.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.loc[:,'price'] = y_hat.round(decimals =2)\n",
    "test_sample.loc[:,['id','price']].to_csv('subm7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = pd.read_csv('subm7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.price = y1.price*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.to_csv('subm8.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.loc[test_sample.subcategory==102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_train_test, y_train, y_train_test = train_test_split(X, y, test_size=0.3, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "rlmse_scorer(regressor, X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# добавляем фичи - существительные и латинские слова (бренды) из названия - первые наиболее часто встречаемые\n",
    "# и биграммы из описания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем название\n",
    "# из описания наиболее часто встречаемые 3-граммы, 2-граммы, 1-граммы\n",
    "morph=pymorphy2.MorphAnalyzer()\n",
    "def getSimpleString(text):\n",
    "    words=[]\n",
    "    tokens=re.findall('[А-Яа-яЁёA-Za-z]+\\-[А-Яа-яЁёA-Za-z]+|[А-Яа-яЁёA-Za-z]+', str(text))\n",
    "    for t in tokens:\n",
    "        pv=morph.parse(t)\n",
    "        for p in pv:\n",
    "            if p.tag.POS in ['ADJF', 'NOUN', 'VERB']:\n",
    "                words.append(p.normal_form)\n",
    "                break\n",
    "            elif p.tag == pymorphy2.tagset.OpencorporaTag('LATN'):\n",
    "                words.append(t)\n",
    "                break\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLatnNounString(text):\n",
    "    words=[]\n",
    "    tokens=re.findall('[А-Яа-яЁёA-Za-z]+\\-[А-Яа-яЁёA-Za-z]+|[А-Яа-яЁёA-Za-z]+', str(text))\n",
    "    for t in tokens:\n",
    "        pv=morph.parse(t)\n",
    "        for p in pv:\n",
    "            if p.tag.POS in ['NOUN']:\n",
    "                words.append(p.normal_form)\n",
    "                break\n",
    "            elif p.tag == pymorphy2.tagset.OpencorporaTag('LATN'):\n",
    "                words.append(t)\n",
    "                break\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_4_col.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['new_name'] = train_df['name'].apply(func = getSimpleString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['new_description'] = train_df['description'].apply(func = getSimpleString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['new_name'].to_csv('new_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['new_description'].to_csv('new_description.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_descr = pd.read_csv('new_description.csv')\n",
    "train_df['new_description'] = new_descr['Unnamed: 1']\n",
    "train_df['new_description'] = train_df['new_description'].apply(lambda x: str(x).replace('век', ''))\n",
    "train_df['new_description'] = train_df['new_description'].apply(lambda x: str(x).replace('секунда', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['new_description'] = test_sample['description'].apply(func = getSimpleString)\n",
    "test_sample['new_description'] = test_sample['new_description'].apply(lambda x: str(x).replace('век', ''))\n",
    "test_sample['new_description'] = test_sample['new_description'].apply(lambda x: str(x).replace('секунда', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['new_name_noun'] = test_sample['name'].apply(func = getLatnNounString)\n",
    "test_sample['new_name_noun'] = test_sample['new_name_noun'].apply(lambda x: str(x).replace('век', ''))\n",
    "test_sample['new_name_noun'] = test_sample['new_name_noun'].apply(lambda x: str(x).replace('секунда', ''))\n",
    "X_test_descr2 = counter_descr2.transform(test_sample['new_description'].values)\n",
    "X_test_name = counter_name.transform(test_sample['new_name_noun'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_descr2 = sp.csr_matrix(X_test_descr2)\n",
    "X_test_name = sp.csr_matrix(X_test_name)\n",
    "X_test = sp.csr_matrix(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sp.csr_matrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = test_df_features.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = sp.csr_matrix(t1)\n",
    "t2 = sp.csr_matrix(X_test_subcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2_n_test = sp.hstack((t1, t2, X_test_name[:,sorted_sum_name_df.index[0:n_name]], X_test_descr2[:,sorted_sum2_df.index[0:n]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = xg_reg.predict(X_2_n_test)\n",
    "test_sample.loc[:,'price'] = y_hat.round(decimals =2)\n",
    "test_sample.loc[:,['id','price']].to_csv('subm9.csv', index=False)\n",
    "test_sample.loc[:,'price'] = test_sample.loc[:,'price']*100\n",
    "test_sample.loc[:,['id','price']].to_csv('subm10.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_descr2 = CountVectorizer(ngram_range=(2,2))\n",
    "X_descr2 = counter_descr2.fit_transform(train_df['new_description'].values)\n",
    "X_descr2 = sp.csr_matrix(X_descr2)\n",
    "sums = X_descr2.sum(axis=0)\n",
    "ngrams2 = counter_descr2.get_feature_names()\n",
    "sum2_df = pd.DataFrame({'ngrams2': ngrams2, 'sums': sums.tolist()[0]})\n",
    "sorted_sum2_df = sum2_df.sort_values(by='sums',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.fromfile(\"x.csv\", sep=\"\\t\")\n",
    "X = X.reshape((1748890, 256))\n",
    "y = pd.read_csv(\"y.csv\",header=None)\n",
    "y=y.iloc[:,1]\n",
    "X = np.delete(X, [0,1,2,4], 1)\n",
    "X = sp.csr_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['new_name_noun'] = train_df['name'].apply(func = getLatnNounString)\n",
    "train_df['new_name_noun'] = train_df['new_name_noun'].apply(lambda x: str(x).replace('век', ''))\n",
    "train_df['new_name_noun'] = train_df['new_name_noun'].apply(lambda x: str(x).replace('секунда', ''))\n",
    "counter_name = CountVectorizer()\n",
    "X_name = counter_name.fit_transform(train_df['new_name_noun'].values)\n",
    "X_name = sp.csr_matrix(X_name)\n",
    "sums_name = X_name.sum(axis=0)\n",
    "ngrams_name = counter_name.get_feature_names()\n",
    "sum_name_df = pd.DataFrame({'ngrams': ngrams_name, 'sums': sums_name.tolist()[0]})\n",
    "sorted_sum_name_df = sum_name_df.sort_values(by='sums',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sum_name_df.to_csv('sorted_sum_name_df.csv')\n",
    "sorted_sum2_df.to_csv('sorted_sum2_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 булевских + субкатегории + n_name первых существительных из названия + n первых биграмм из описания\n",
    "n = 500\n",
    "n_name = 1000\n",
    "#X_2_n = sp.hstack((X, X_name[:,sorted_sum_name_df.index[0:n_name]], X_descr2[:,sorted_sum2_df.index[0:n]]))\n",
    "X_2_n = sp.hstack((X, X_name, X_descr2))\n",
    "\n",
    "X_train, X_train_test, y_train, y_train_test = train_test_split(X_2_n, y, test_size=0.3, random_state=111)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "rlmse_scorer(regressor, X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление строк в csr_matrix\n",
    "def delete_rows_csr(mat, indices):\n",
    "    \"\"\"\n",
    "    Remove the rows denoted by ``indices`` form the CSR sparse matrix ``mat``.\n",
    "    \"\"\"\n",
    "    if not isinstance(mat, sp.csr_matrix):\n",
    "        raise ValueError(\"works only for CSR format -- use .tocsr() first\")\n",
    "    indices = list(indices)\n",
    "    mask = np.ones(mat.shape[0], dtype=bool)\n",
    "    mask[indices] = False\n",
    "    return mat[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = good.index[good == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_anom = delete_rows_csr(X_2_n.tocsr(), indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_anom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_anom = y.loc[good == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_anom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "rlmse_scorer(regressor, X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n = 2000 5.302126782142029\n",
    "#n = 1000  5.302126782142029\n",
    "#n=500 5.294529658685628\n",
    "#n=200 5.33351401196549\n",
    "#n=100 5.367065667856761\n",
    "\n",
    "#n=500\n",
    "#добавим n_name\n",
    "#n_name = 1000 5.1358093668948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "n_name = 1000\n",
    "X_2_n = sp.hstack((X, X_name[:,sorted_sum_name_df.index[0:n_name]], X_descr2[:,sorted_sum2_df.index[0:n]]))\n",
    "X_train, X_train_test, y_train, y_train_test = train_test_split(X_2_n, y, test_size=0.3, random_state=111)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.005,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 10)\n",
    "\n",
    "\n",
    "xg_reg.fit(X_2_n, y)\n",
    "\n",
    "#rlmse_scorer(xg_reg, X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5, n_name = 10\n",
    "max_depth\n",
    "5 5.66153325033493 \n",
    "\n",
    "max_depth 10 learn 0.005 3.3807009004878967\n",
    "\n",
    "n = 500 n_name = 10\n",
    "3.3675370599640186\n",
    "\n",
    "n = 500 n_name = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data_dmatrix = xgb.DMatrix(data=X_2_n,label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xg_reg)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим что без аномалий\n",
    "train_df2 = pd.read_csv('train_4_col_2.csv', delimiter='\\t')\n",
    "train_df['subcategory'] = train_df2['subcategory']\n",
    "good = train_df.groupby(\"subcategory\").price.\\\n",
    "      transform(lambda x : (x<x.quantile(0.95))&(x>(x.quantile(0.05)))).eq(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_tr = pd.concat([pd.DataFrame(X_2_n.toarray()), good], axis=1)\n",
    "X_train, X_train_test, y_train, y_train_test = train_test_split(X_tr, y, test_size=0.3, random_state=111)\n",
    "y_train = y_train.loc[X_train.price == True]\n",
    "X_train = X_train.loc[X_train.price == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.iloc[:,0:1752]\n",
    "X_train_test = X_train_test.iloc[:,0:1752]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(X_2_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subm 11 - без anomalies\n",
    "xg_reg.fit(X_anom, y_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = xg_reg.predict(X_2_n_test)\n",
    "test_sample.loc[:,'price'] = y_hat.round(decimals =2)\n",
    "test_sample.loc[:,['id','price']].to_csv('subm11.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
